{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from scraper.Comment import Comment\n",
    "from scraper.JsonLoader import JsonLoader\n",
    "from scraper.RedditJsonLoader import RedditJsonLoader\n",
    "from scraper.RawCommentParser import RawCommentParser\n",
    "from scraper.RedditCommentLoader import RedditCommentLoader\n",
    "from scraper.RedditCommentSerializer import RedditCommentSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_comments(comments, level=0):\n",
    "    for comment in comments:\n",
    "        print('  ' * level + comment.body)\n",
    "        print_comments(comment.children, level + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_mode_and_path(mode, local_data_path):\n",
    "    \"\"\"\n",
    "    Validate the mode and local data path to ensure they are compatible.\n",
    "    \n",
    "    Args:\n",
    "        mode (str): The mode to use ('RAW_JSON', 'JSON', 'URL', 'CSV')\n",
    "        local_data_path (str): Path to the local data file\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if valid, False otherwise\n",
    "    \"\"\"\n",
    "    # Define supported modes and file extensions\n",
    "    supported_modes = ['RAW_JSON', 'JSON', 'URL', 'CSV']\n",
    "    file_extensions = {\n",
    "        'json': ['JSON', 'RAW_JSON'],\n",
    "        'csv': ['CSV']\n",
    "    }\n",
    "\n",
    "    # Validate the mode\n",
    "    if mode not in supported_modes:\n",
    "        print(f'Invalid mode: Select one of {\", \".join(supported_modes)}')\n",
    "        return False\n",
    "\n",
    "    # For non-URL modes, validate that the file exists and has matching extension\n",
    "    if mode != 'URL':\n",
    "        if not os.path.exists(local_data_path):\n",
    "            print('Local data file not found. LOCAL_DATA_PATH must be set for any mode other than URL')\n",
    "            return False\n",
    "        \n",
    "        # Check if file extension matches the mode\n",
    "        file_ext = os.path.splitext(local_data_path)[1].lower().replace('.', '')\n",
    "        valid_modes = file_extensions.get(file_ext, [])\n",
    "        \n",
    "        if mode not in valid_modes:\n",
    "            print(f'Mode {mode} is not compatible with file extension .{file_ext}')\n",
    "            print(f'For .{file_ext} files, use one of: {\", \".join(valid_modes)}')\n",
    "            return False\n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 for close to 40 years. I’m on a Tandem TSlim pump with a Dexcom G6. I have been on Mounjaro for close to 18 months. My daily insulin usage almost immediately went from 110-120 units a day to 40-50. My A1C went from a 7.6 to a 5.6. It was a 6.0 4 months after starting Mounjaro. I’ve also lost 85-90 pounds. These drugs are a game changer for T1 management. I haven’t had any serious side effects and I’ve never increased my dosage past 7.5.\n",
      "  Very similar results for me, too\n",
      "  My experience is almost identical to this as well. The only thing that has ever improved my control/health as much as GLP-1 drugs is when I switched to a CGM that integrated with my pump (also on tandem + dexcom combo).\n",
      "  Pretty much my results except my A1c is lower and I only lost sixty pounds. I think everyone should take mounjaro if possible. It’s a miracle drug.\n",
      "  T1 40+ years. Went from TTD around 45-55 units a day to 25-40. Lost 45 pounds. Ozempic also reduces inflammation so it takes away that round face that many women with T1 have, and helps with trigger finger and arthritis\n",
      "  no you notice more lows? or have you been able to flatline?  my a1c is pretty low right now but my endo and i both know its because i have too many lows.\n",
      "    Yes I’ve experienced more lows but that is expected since I’m maintaining tighter control and my blood sugar isn’t going high that often. Additionally, I’m more active now than I have been in years.\n",
      "  Does your insurance cover it? Is your co-pay astronomical?\n",
      "    $25 copay. They cover it but my doctor had to complete a prior authorization.\n"
     ]
    }
   ],
   "source": [
    "# Get mode and local data path\n",
    "mode = os.getenv('MODE', 'URL')\n",
    "output_path = os.getenv('BASE_PATH', 'Dataset/output')\n",
    "local_data_path = None\n",
    "if mode == 'URL':\n",
    "    local_data_path = None  # Not needed for URL mode\n",
    "elif mode == 'CSV':\n",
    "    local_data_path = os.getenv('LOCAL_DATA_PATH', 'Dataset/sample/comments.csv')\n",
    "else:  # JSON or RAW_JSON modes\n",
    "    local_data_path = os.getenv('LOCAL_DATA_PATH', 'Dataset/sample/reddit.json')\n",
    "\n",
    "if not validate_mode_and_path(mode, local_data_path):\n",
    "    exit(1)\n",
    "\n",
    "data = None\n",
    "comments = None\n",
    "if mode == 'RAW_JSON':\n",
    "    json_loader = JsonLoader()\n",
    "    data = json_loader.load_raw(local_data_path)\n",
    "    comments: List[Comment] = RawCommentParser().parse_comments(data)\n",
    "elif mode == 'JSON':\n",
    "    json_loader = RedditJsonLoader()\n",
    "    comments: List[Comment] = json_loader.load_comments(local_data_path)\n",
    "elif mode == 'URL':\n",
    "    example_url =\\\n",
    "        'https://www.reddit.com/r/diabetes_t1/comments/1h9k636/type_1s_who_have_taken_ozempic_what_was_your/'\n",
    "    data = RedditCommentLoader().get_comments(example_url)\n",
    "    comments: List[Comment] = RawCommentParser().parse_comments(data)\n",
    "elif mode == 'CSV':\n",
    "    print('Use \"df = pd.read_csv(csv_filename)\" to load the CSV file into a DataFrame')\n",
    "    df = pd.read_csv(local_data_path)\n",
    "else:\n",
    "    print('Invalid mode')\n",
    "    exit(1)\n",
    "\n",
    "print_comments(comments[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (107, 11)\n",
      "Columns: Index(['id', 'author', 'body', 'created_utc', 'score', 'parent_id', 'depth',\n",
      "       'ups', 'downs', 'num_reports', 'report_reasons'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 107 entries, 0 to 106\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              107 non-null    object \n",
      " 1   author          107 non-null    object \n",
      " 2   body            107 non-null    object \n",
      " 3   created_utc     107 non-null    float64\n",
      " 4   score           107 non-null    int64  \n",
      " 5   parent_id       107 non-null    object \n",
      " 6   depth           107 non-null    int64  \n",
      " 7   ups             107 non-null    int64  \n",
      " 8   downs           107 non-null    int64  \n",
      " 9   num_reports     0 non-null      object \n",
      " 10  report_reasons  0 non-null      object \n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 9.3+ KB\n"
     ]
    }
   ],
   "source": [
    "serializer = RedditCommentSerializer()\n",
    "df = serializer.to_dataframe(comments)\n",
    "\n",
    "print(f'Dataframe shape: {df.shape}')\n",
    "print(f'Columns: {df.columns}')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Uncomment to test the export functionality\\ntimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\")\\nif not os.path.exists(output_path):\\n    os.makedirs(output_path)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Uncomment to test the export functionality\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Uncomment to save the comments to a CSV file\\ncsv_filename = os.path.join(output_path, f\\'{timestamp}_comments.csv\\')\\nserializer.write_to_csv(comments, csv_filename)\\n\\nprint(f\"Comments saved to {csv_filename}\")\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Uncomment to save the comments to a CSV file\n",
    "csv_filename = os.path.join(output_path, f'{timestamp}_comments.csv')\n",
    "serializer.write_to_csv(comments, csv_filename)\n",
    "\n",
    "print(f\"Comments saved to {csv_filename}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Uncomment to save as JSON\\njson_filename = os.path.join(output_path, f\\'{timestamp}_comments.json\\')\\nserializer.write_to_json(comments, json_filename)\\n\\nprint(f\"Comments saved to {json_filename}\")\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Uncomment to save as JSON\n",
    "json_filename = os.path.join(output_path, f'{timestamp}_comments.json')\n",
    "serializer.write_to_json(comments, json_filename)\n",
    "\n",
    "print(f\"Comments saved to {json_filename}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Uncomment to test loading the CSV file\\ndf = pd.read_csv(csv_filename)\\ndf.head()\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Uncomment to test loading the CSV file\n",
    "df = pd.read_csv(csv_filename)\n",
    "df.head()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
