{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from typing import Dict, List\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Comment:\n",
    "    \"\"\" Dataclass for a Reddit comment \"\"\"\n",
    "    _id: str\n",
    "    author: str\n",
    "    body: str\n",
    "    created_utc: int\n",
    "    score: int\n",
    "    parent_id: str | None\n",
    "    depth: int\n",
    "    ups: int\n",
    "    downs: int\n",
    "    num_reports: int | None\n",
    "    report_reasons: str | None\n",
    "    children: List['Comment']\n",
    "\n",
    "    def to_dict(self) -> Dict:\n",
    "        return {\n",
    "            'id': self._id,\n",
    "            'author': self.author,\n",
    "            'body': self.body,\n",
    "            'created_utc': self.created_utc,\n",
    "            'score': self.score,\n",
    "            'parent_id': self.parent_id,\n",
    "            'depth': self.depth,\n",
    "            'ups': self.ups,\n",
    "            'downs': self.downs,\n",
    "            'num_reports': self.num_reports,\n",
    "            'report_reasons': self.report_reasons,\n",
    "            # 'children': [c.to_dict() for c in self.children] # Omitted because the serializers handle this recursively\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, dict: Dict) -> 'Comment':\n",
    "        return cls(\n",
    "            _id=dict['id'],\n",
    "            author=dict['author'],\n",
    "            body=dict['body'],\n",
    "            created_utc=dict['created_utc'],\n",
    "            score=dict['score'],\n",
    "            parent_id=dict['parent_id'],\n",
    "            depth=dict['depth'],\n",
    "            ups=dict['ups'],\n",
    "            downs=dict['downs'],\n",
    "            num_reports=dict['num_reports'],\n",
    "            report_reasons=dict['report_reasons'],\n",
    "            children=[cls.from_dict(c) for c in dict.get('children', [])]\n",
    "        )\n",
    "\n",
    "class RedditCommentLoader:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _clean_url(self, url: str) -> str:\n",
    "        # Add .json to the URL if not already present\n",
    "        if not url.endswith('.json'):\n",
    "            if url.endswith('/'):\n",
    "                url = url + '.json'\n",
    "            else:\n",
    "                url = url + '/.json'\n",
    "        return url\n",
    "\n",
    "    def get_comments(self, url) -> List[Dict]:\n",
    "        url = self._clean_url(url)\n",
    "        # Set a user agent to avoid being blocked\n",
    "        headers = {\n",
    "            'User-Agent': 'python:reddit-comment-loader:v1.0 (by /u/yourname)'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                print(f\"Error fetching comments: HTTP {response.status_code}\")\n",
    "                return None\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request error: {e}\")\n",
    "            return None\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON decode error: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonLoader:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load_raw(self, path) -> List[Dict]:\n",
    "        if not os.path.exists(path):\n",
    "            return None\n",
    "        with open(path, 'r') as file:\n",
    "            return json.load(file)\n",
    "\n",
    "class RedditJsonLoader(JsonLoader):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "    \n",
    "    def load_comments(self, path) -> List[Comment]:\n",
    "        raw = self.load_raw(path)\n",
    "        if raw is None:\n",
    "            return None\n",
    "        return [Comment.from_dict(comment) for comment in raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedditCommentSerializer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def write_to_csv(self, comments: List[Comment], path: str) -> None:\n",
    "        \"\"\"Write comments to a CSV file\"\"\"\n",
    "        flat_comments = self._flatten_comments(comments)\n",
    "        fieldnames = Comment.__dataclass_fields__.keys()\n",
    "        fieldnames = [field if field != '_id' else 'id' for field in fieldnames] # Replace _id with id for CSV header\n",
    "        fieldnames.remove('children') # Remove children field from CSV\n",
    "        with open(path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for comment in flat_comments:\n",
    "                writer.writerow(comment)\n",
    "\n",
    "    def write_to_json(self, comments: List[Comment], path: str) -> None:\n",
    "        \"\"\"Write comments to a JSON file\"\"\"\n",
    "        flat_comments = self._flatten_comments(comments)\n",
    "        \n",
    "        with open(path, 'w', encoding='utf-8') as file:\n",
    "            json.dump(flat_comments, file, indent=4)\n",
    "        \n",
    "    def _flatten_comments(self, comments: List[Comment], parent_id=None, depth=0) -> List[Dict]:\n",
    "        \"\"\"Convert nested comment structure to flat list for serialization\"\"\"\n",
    "        flat_list = []\n",
    "        \n",
    "        for comment in comments:\n",
    "            comment_dict = comment.to_dict()\n",
    "            flat_list.append(comment_dict)\n",
    "            \n",
    "            # Add children recursively\n",
    "            if comment.children:\n",
    "                flat_list.extend(self._flatten_comments(\n",
    "                    comment.children, \n",
    "                    parent_id=comment._id,\n",
    "                    depth=depth+1\n",
    "                ))\n",
    "        \n",
    "        return flat_list\n",
    "    \n",
    "    def to_dataframe(self, comments: List[Comment]):\n",
    "        \"\"\"Convert comments to pandas DataFrame\"\"\"\n",
    "        flat_comments = self._flatten_comments(comments)\n",
    "        return pd.DataFrame(flat_comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawCommentParser:\n",
    "    def __init__(self):\n",
    "        self.comments = []\n",
    "\n",
    "    def parse_comments(self, data: dict) -> List[Comment]:\n",
    "        \"\"\"Parse comments from Reddit API response\"\"\"\n",
    "        self.comments = []\n",
    "        \n",
    "        # Reddit API returns two listings: post and comments\n",
    "        if len(data) >= 2 and 'data' in data[1]:\n",
    "            comments_data = data[1]['data']\n",
    "            if 'children' in comments_data:\n",
    "                for child in comments_data['children']:\n",
    "                    if child['kind'] == 't1':  # t1 is comment type\n",
    "                        comment_data = child['data']\n",
    "                        comment = self._create_comment_from_json(comment_data)\n",
    "                        self.comments.append(comment)\n",
    "                        \n",
    "                        # Parse replies if they exist\n",
    "                        if 'replies' in comment_data and comment_data['replies']:\n",
    "                            if isinstance(comment_data['replies'], dict) and 'data' in comment_data['replies']:\n",
    "                                self._parse_replies(comment_data['replies']['data']['children'], comment)\n",
    "        \n",
    "        return self.comments\n",
    "    \n",
    "    def _parse_replies(self, replies_data, parent_comment) -> None:\n",
    "        \"\"\"Recursively parse nested replies\"\"\"\n",
    "        for reply in replies_data:\n",
    "            if reply['kind'] == 't1':\n",
    "                reply_data = reply['data']\n",
    "                reply_comment = self._create_comment_from_json(reply_data)\n",
    "                parent_comment.children.append(reply_comment)\n",
    "                \n",
    "                # Recursively parse nested replies\n",
    "                if 'replies' in reply_data and reply_data['replies']:\n",
    "                    if isinstance(reply_data['replies'], dict) and 'data' in reply_data['replies']:\n",
    "                        self._parse_replies(reply_data['replies']['data']['children'], reply_comment)\n",
    "\n",
    "    def _create_comment_from_json(self, data: dict) -> Comment:\n",
    "        return Comment(\n",
    "            _id=data.get('id', ''),\n",
    "            author=data.get('author', ''),\n",
    "            body=data.get('body', ''),\n",
    "            created_utc=data.get('created_utc', 0),\n",
    "            score=data.get('score', 0),\n",
    "            parent_id=data.get('parent_id', None),\n",
    "            depth=data.get('depth', 0),\n",
    "            ups=data.get('ups', 0),\n",
    "            downs=data.get('downs', 0),\n",
    "            num_reports=data.get('num_reports', None),\n",
    "            report_reasons=data.get('report_reasons', None),\n",
    "            children=[]\n",
    "        )\n",
    "    \n",
    "def print_comments(comments, level=0):\n",
    "    for comment in comments:\n",
    "        print('  ' * level + comment.body)\n",
    "        print_comments(comment.children, level + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_mode_and_path(mode, local_data_path):\n",
    "    \"\"\"\n",
    "    Validate the mode and local data path to ensure they are compatible.\n",
    "    \n",
    "    Args:\n",
    "        mode (str): The mode to use ('RAW_JSON', 'JSON', 'URL', 'CSV')\n",
    "        local_data_path (str): Path to the local data file\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if valid, False otherwise\n",
    "    \"\"\"\n",
    "    # Define supported modes and file extensions\n",
    "    supported_modes = ['RAW_JSON', 'JSON', 'URL', 'CSV']\n",
    "    file_extensions = {\n",
    "        'json': ['JSON', 'RAW_JSON'],\n",
    "        'csv': ['CSV']\n",
    "    }\n",
    "\n",
    "    # Validate the mode\n",
    "    if mode not in supported_modes:\n",
    "        print(f'Invalid mode: Select one of {\", \".join(supported_modes)}')\n",
    "        return False\n",
    "\n",
    "    # For non-URL modes, validate that the file exists and has matching extension\n",
    "    if mode != 'URL':\n",
    "        if not os.path.exists(local_data_path):\n",
    "            print('Local data file not found. LOCAL_DATA_PATH must be set for any mode other than URL')\n",
    "            return False\n",
    "        \n",
    "        # Check if file extension matches the mode\n",
    "        file_ext = os.path.splitext(local_data_path)[1].lower().replace('.', '')\n",
    "        valid_modes = file_extensions.get(file_ext, [])\n",
    "        \n",
    "        if mode not in valid_modes:\n",
    "            print(f'Mode {mode} is not compatible with file extension .{file_ext}')\n",
    "            print(f'For .{file_ext} files, use one of: {\", \".join(valid_modes)}')\n",
    "            return False\n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 for close to 40 years. I’m on a Tandem TSlim pump with a Dexcom G6. I have been on Mounjaro for close to 18 months. My daily insulin usage almost immediately went from 110-120 units a day to 40-50. My A1C went from a 7.6 to a 5.6. It was a 6.0 4 months after starting Mounjaro. I’ve also lost 85-90 pounds. These drugs are a game changer for T1 management. I haven’t had any serious side effects and I’ve never increased my dosage past 7.5.\n",
      "  Very similar results for me, too\n",
      "  My experience is almost identical to this as well. The only thing that has ever improved my control/health as much as GLP-1 drugs is when I switched to a CGM that integrated with my pump (also on tandem + dexcom combo).\n",
      "  Pretty much my results except my A1c is lower and I only lost sixty pounds. I think everyone should take mounjaro if possible. It’s a miracle drug.\n",
      "  T1 40+ years. Went from TTD around 45-55 units a day to 25-40. Lost 45 pounds. Ozempic also reduces inflammation so it takes away that round face that many women with T1 have, and helps with trigger finger and arthritis\n",
      "  no you notice more lows? or have you been able to flatline?  my a1c is pretty low right now but my endo and i both know its because i have too many lows.\n",
      "    Yes I’ve experienced more lows but that is expected since I’m maintaining tighter control and my blood sugar isn’t going high that often. Additionally, I’m more active now than I have been in years.\n",
      "  Does your insurance cover it? Is your co-pay astronomical?\n",
      "    $25 copay. They cover it but my doctor had to complete a prior authorization.\n"
     ]
    }
   ],
   "source": [
    "# Get mode and local data path\n",
    "mode = os.getenv('MODE', 'URL')\n",
    "output_path = os.getenv('BASE_PATH', 'output')\n",
    "local_data_path = None\n",
    "if mode == 'URL':\n",
    "    local_data_path = None  # Not needed for URL mode\n",
    "elif mode == 'CSV':\n",
    "    local_data_path = os.getenv('LOCAL_DATA_PATH', 'sample/comments.csv')\n",
    "else:  # JSON or RAW_JSON modes\n",
    "    local_data_path = os.getenv('LOCAL_DATA_PATH', 'sample/reddit.json')\n",
    "\n",
    "if not validate_mode_and_path(mode, local_data_path):\n",
    "    exit(1)\n",
    "\n",
    "data = None\n",
    "comments = None\n",
    "if mode == 'RAW_JSON':\n",
    "    json_loader = JsonLoader()\n",
    "    data = json_loader.load_raw(local_data_path)\n",
    "    comments = RawCommentParser().parse_comments(data)\n",
    "elif mode == 'JSON':\n",
    "    json_loader = RedditJsonLoader()\n",
    "    comments = json_loader.load_comments(local_data_path)\n",
    "elif mode == 'URL':\n",
    "    example_url = 'https://www.reddit.com/r/diabetes_t1/comments/1h9k636/type_1s_who_have_taken_ozempic_what_was_your/'\n",
    "    data = RedditCommentLoader().get_comments(example_url)\n",
    "    comments = RawCommentParser().parse_comments(data)\n",
    "elif mode == 'CSV':\n",
    "    print('CSV mode not implemented')\n",
    "    exit(1)\n",
    "else:\n",
    "    print('Invalid mode')\n",
    "    exit(1)\n",
    "\n",
    "print_comments(comments[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 107 entries, 0 to 106\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              107 non-null    object \n",
      " 1   author          107 non-null    object \n",
      " 2   body            107 non-null    object \n",
      " 3   created_utc     107 non-null    float64\n",
      " 4   score           107 non-null    int64  \n",
      " 5   parent_id       107 non-null    object \n",
      " 6   depth           107 non-null    int64  \n",
      " 7   ups             107 non-null    int64  \n",
      " 8   downs           107 non-null    int64  \n",
      " 9   num_reports     0 non-null      object \n",
      " 10  report_reasons  0 non-null      object \n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 9.3+ KB\n"
     ]
    }
   ],
   "source": [
    "serializer = RedditCommentSerializer()\n",
    "df = serializer.to_dataframe(comments)\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments saved to output/2025-03-16_23_22_47_comments.csv\n"
     ]
    }
   ],
   "source": [
    "csv_filename = os.path.join(output_path, f'{timestamp}_comments.csv')\n",
    "\n",
    "serializer.write_to_csv(comments, csv_filename)\n",
    "\n",
    "print(f\"Comments saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments saved to output/2025-03-16_23_22_47_comments.json\n"
     ]
    }
   ],
   "source": [
    "json_filename = os.path.join(output_path, f'{timestamp}_comments.json')\n",
    "\n",
    "serializer.write_to_json(comments, json_filename)\n",
    "\n",
    "print(f\"Comments saved to {json_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>depth</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>num_reports</th>\n",
       "      <th>report_reasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m11jg92</td>\n",
       "      <td>HoboMinion</td>\n",
       "      <td>T1 for close to 40 years. I’m on a Tandem TSli...</td>\n",
       "      <td>1.733672e+09</td>\n",
       "      <td>75</td>\n",
       "      <td>t3_1h9k636</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m11wwzr</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Very similar results for me, too</td>\n",
       "      <td>1.733677e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>t1_m11jg92</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m125nhw</td>\n",
       "      <td>BjergerPresident</td>\n",
       "      <td>My experience is almost identical to this as w...</td>\n",
       "      <td>1.733679e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>t1_m11jg92</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m139z5u</td>\n",
       "      <td>MaggieNFredders</td>\n",
       "      <td>Pretty much my results except my A1c is lower ...</td>\n",
       "      <td>1.733692e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>t1_m11jg92</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m17vfp7</td>\n",
       "      <td>OranjellosBroLemonj</td>\n",
       "      <td>T1 40+ years. Went from TTD around 45-55 units...</td>\n",
       "      <td>1.733764e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>t1_m11jg92</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id               author  \\\n",
       "0  m11jg92           HoboMinion   \n",
       "1  m11wwzr            [deleted]   \n",
       "2  m125nhw     BjergerPresident   \n",
       "3  m139z5u      MaggieNFredders   \n",
       "4  m17vfp7  OranjellosBroLemonj   \n",
       "\n",
       "                                                body   created_utc  score  \\\n",
       "0  T1 for close to 40 years. I’m on a Tandem TSli...  1.733672e+09     75   \n",
       "1                   Very similar results for me, too  1.733677e+09      9   \n",
       "2  My experience is almost identical to this as w...  1.733679e+09      6   \n",
       "3  Pretty much my results except my A1c is lower ...  1.733692e+09      3   \n",
       "4  T1 40+ years. Went from TTD around 45-55 units...  1.733764e+09      3   \n",
       "\n",
       "    parent_id  depth  ups  downs  num_reports  report_reasons  \n",
       "0  t3_1h9k636      0   75      0          NaN             NaN  \n",
       "1  t1_m11jg92      1    9      0          NaN             NaN  \n",
       "2  t1_m11jg92      1    6      0          NaN             NaN  \n",
       "3  t1_m11jg92      1    3      0          NaN             NaN  \n",
       "4  t1_m11jg92      1    3      0          NaN             NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_filename)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
